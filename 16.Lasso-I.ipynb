{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 21613\n",
      "PROGRESS: Number of features          : 17\n",
      "PROGRESS: Number of unpacked features : 17\n",
      "PROGRESS: Number of coefficients    : 18\n",
      "PROGRESS: Starting Accelerated Gradient (FISTA)\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: Tuning step size. First iteration could take longer than subsequent iterations.\n",
      "PROGRESS: | 1         | 2        | 0.000002  | 1.452101     | 6962915.603493     | 426631.749026 |\n",
      "PROGRESS: | 2         | 3        | 0.000002  | 1.487265     | 6843144.200219     | 392488.929838 |\n",
      "PROGRESS: | 3         | 4        | 0.000002  | 1.522047     | 6831900.032123     | 385340.166783 |\n",
      "PROGRESS: | 4         | 5        | 0.000002  | 1.558051     | 6847166.848958     | 384842.383767 |\n",
      "PROGRESS: | 5         | 6        | 0.000002  | 1.592545     | 6869667.895833     | 385998.458623 |\n",
      "PROGRESS: | 6         | 7        | 0.000002  | 1.628429     | 6847177.773672     | 380824.455891 |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: TERMINATED: Iteration limit reached.\n",
      "PROGRESS: This model may not be optimal. To improve it, consider increasing `max_iterations`.\n"
     ]
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+\n",
      "|       name       | index |     value     |\n",
      "+------------------+-------+---------------+\n",
      "|   (intercept)    |  None |  274873.05595 |\n",
      "|     bedrooms     |  None |      0.0      |\n",
      "| bedrooms_square  |  None |      0.0      |\n",
      "|    bathrooms     |  None | 8468.53108691 |\n",
      "|   sqft_living    |  None | 24.4207209824 |\n",
      "| sqft_living_sqrt |  None | 350.060553386 |\n",
      "|     sqft_lot     |  None |      0.0      |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |\n",
      "|      floors      |  None |      0.0      |\n",
      "|  floors_square   |  None |      0.0      |\n",
      "|    waterfront    |  None |      0.0      |\n",
      "|       view       |  None |      0.0      |\n",
      "|    condition     |  None |      0.0      |\n",
      "|      grade       |  None | 842.068034898 |\n",
      "|    sqft_above    |  None | 20.0247224171 |\n",
      "|  sqft_basement   |  None |      0.0      |\n",
      "|     yr_built     |  None |      0.0      |\n",
      "+------------------+-------+---------------+\n",
      "[18 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_all.get(\"coefficients\").print_rows(num_rows = len(all_features)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.0, 625766285142461.2], [31.622776601683793, 625766285362395.2], [100.0, 625766286057887.0], [316.22776601683796, 625766288257224.9], [1000.0, 625766295212186.0], [3162.2776601683795, 625766317206077.8], [10000.0, 625766386760661.5], [31622.776601683792, 625766606749281.4], [100000.0, 625767302791633.4], [316227.76601683791, 625769507643885.1], [1000000.0, 625776517727025.8], [3162277.6601683795, 625799062845466.9], [10000000.0, 625883719085424.5]]\n"
     ]
    }
   ],
   "source": [
    "stor = []    \n",
    "for l1_penalty in np.logspace(1, 7, num=13):\n",
    "    model =  graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None,l2_penalty=0., l1_penalty=l1_penalty,verbose = False)\n",
    "    prediction = model.predict(validation)\n",
    "    e = validation[\"price\"] - prediction\n",
    "    RSS = sum(e*e)\n",
    "    stor.append([l1_penalty,RSS])\n",
    "    \n",
    "#print stor        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -----------> 6.25766285142e+14 ====== 10.0\n",
      "1 -----------> 6.25766285362e+14 ====== 31.6227766017\n",
      "2 -----------> 6.25766286058e+14 ====== 100.0\n",
      "3 -----------> 6.25766288257e+14 ====== 316.227766017\n",
      "4 -----------> 6.25766295212e+14 ====== 1000.0\n",
      "5 -----------> 6.25766317206e+14 ====== 3162.27766017\n",
      "6 -----------> 6.25766386761e+14 ====== 10000.0\n",
      "7 -----------> 6.25766606749e+14 ====== 31622.7766017\n",
      "8 -----------> 6.25767302792e+14 ====== 100000.0\n",
      "9 -----------> 6.25769507644e+14 ====== 316227.766017\n",
      "10 -----------> 6.25776517727e+14 ====== 1000000.0\n",
      "11 -----------> 6.25799062845e+14 ====== 3162277.66017\n",
      "12 -----------> 6.25883719085e+14 ====== 10000000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11069e810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(len(stor)):\n",
    "    print k,\"----------->\",stor[k][1],\"======\", stor[k][0]\n",
    "    plt.scatter(k,stor[k][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 21613\n",
      "PROGRESS: Number of features          : 17\n",
      "PROGRESS: Number of unpacked features : 17\n",
      "PROGRESS: Number of coefficients    : 18\n",
      "PROGRESS: Starting Accelerated Gradient (FISTA)\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: Tuning step size. First iteration could take longer than subsequent iterations.\n",
      "PROGRESS: | 1         | 2        | 0.000002  | 0.408038     | 6306018.232993     | 313413.344721 |\n",
      "PROGRESS: | 2         | 3        | 0.000002  | 0.442501     | 6019513.777487     | 293369.342637 |\n",
      "PROGRESS: | 3         | 4        | 0.000002  | 0.477943     | 5903592.015248     | 288639.744638 |\n",
      "PROGRESS: | 4         | 5        | 0.000002  | 0.513448     | 5830435.640662     | 284383.788655 |\n",
      "PROGRESS: | 5         | 6        | 0.000002  | 0.548040     | 5757083.459662     | 280315.641755 |\n",
      "PROGRESS: | 6         | 7        | 0.000002  | 0.582469     | 5678327.292256     | 276610.230084 |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: TERMINATED: Iteration limit reached.\n",
      "PROGRESS: This model may not be optimal. To improve it, consider increasing `max_iterations`.\n"
     ]
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+\n",
      "|       name       | index |      value       |\n",
      "+------------------+-------+------------------+\n",
      "|   (intercept)    |  None |  20459.2475219   |\n",
      "|     bedrooms     |  None |  8155.38098737   |\n",
      "| bedrooms_square  |  None |  1479.73787423   |\n",
      "|    bathrooms     |  None |  24576.2383172   |\n",
      "|   sqft_living    |  None |  37.4911504798   |\n",
      "| sqft_living_sqrt |  None |  1109.39597073   |\n",
      "|     sqft_lot     |  None | -0.0168499198461 |\n",
      "|  sqft_lot_sqrt   |  None |  149.569423985   |\n",
      "|      floors      |  None |  20983.5137368   |\n",
      "|  floors_square   |  None |  12278.1023451   |\n",
      "|    waterfront    |  None |  581971.306649   |\n",
      "|       view       |  None |  92988.9899686   |\n",
      "|    condition     |  None |  6924.28719657   |\n",
      "|      grade       |  None |  6205.64105779   |\n",
      "|    sqft_above    |  None |  41.3497390696   |\n",
      "|  sqft_basement   |  None |   118.23242135   |\n",
      "|     yr_built     |  None |  10.1881669529   |\n",
      "+------------------+-------+------------------+\n",
      "[18 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_all.get(\"coefficients\").print_rows(num_rows = len(all_features)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stor_2 = []\n",
    "for l1_penalty in np.logspace(8, 10, num=20):\n",
    "    model =  graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None,l2_penalty=0., l1_penalty=l1_penalty,verbose = False)\n",
    "    coeff = model['coefficients']['value']\n",
    "    nb = coeff.nnz()\n",
    "    stor_2.append([l1_penalty,nb])\n",
    "    if nb ==7:\n",
    "        print l1_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100000000.0, 18],\n",
       " [127427498.57031322, 18],\n",
       " [162377673.91887242, 18],\n",
       " [206913808.11147901, 18],\n",
       " [263665089.87303555, 17],\n",
       " [335981828.62837881, 17],\n",
       " [428133239.8719396, 17],\n",
       " [545559478.11685145, 17],\n",
       " [695192796.17755914, 17],\n",
       " [885866790.41008317, 16],\n",
       " [1128837891.6846883, 15],\n",
       " [1438449888.2876658, 15],\n",
       " [1832980710.8324375, 13],\n",
       " [2335721469.0901213, 12],\n",
       " [2976351441.6313133, 10],\n",
       " [3792690190.7322536, 6],\n",
       " [4832930238.5717525, 5],\n",
       " [6158482110.6602545, 3],\n",
       " [7847599703.5146227, 1],\n",
       " [10000000000.0, 1]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = 2976351441.6313133\n",
    "l1_penalty_max = 3792690190.7322536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3448968612.16\n",
      "3491933809.48\n",
      "3534899006.81\n",
      "3577864204.13\n"
     ]
    }
   ],
   "source": [
    "stor_3 = []\n",
    "stor_4 = []\n",
    "for l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "    model =  graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                                validation_set=None,l2_penalty=0., l1_penalty=l1_penalty,verbose = False)\n",
    "   \n",
    "    #---------- find coeff----------------------                                           \n",
    "    coeff = model['coefficients']['value']\n",
    "    nb = coeff.nnz()\n",
    "    stor_4.append([l1_penalty,nb])\n",
    "                                               \n",
    "    if nb ==7:\n",
    "        print l1_penalty                                         \n",
    "        prediction = model.predict(validation)\n",
    "        e = validation[\"price\"] - prediction\n",
    "        RSS = sum(e*e)\n",
    "        stor_3.append([l1_penalty,RSS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3448968612.1634369, 1046937488751713.6],\n",
       " [3491933809.484539, 1051147625612863.0],\n",
       " [3534899006.8056412, 1055992735342999.2],\n",
       " [3577864204.1267428, 1060799531763290.2]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stor_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 -----------> 1.04693748875e+15 ====== 3448968612.16\n",
      "1 -----------> 1.05114762561e+15 ====== 3491933809.48\n",
      "2 -----------> 1.05599273534e+15 ====== 3534899006.81\n",
      "3 -----------> 1.06079953176e+15 ====== 3577864204.13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQ1xRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110f2d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(len(stor_3)):\n",
    "    print k,\"----------->\",stor_3[k][1],\"======\", stor_3[k][0]\n",
    "    plt.scatter(k,stor_3[k][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_last =  graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None,l2_penalty=0., l1_penalty=3448968612.1,verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+\n",
      "|       name       | index |     value     |\n",
      "+------------------+-------+---------------+\n",
      "|   (intercept)    |  None | 222253.192544 |\n",
      "|     bedrooms     |  None | 661.722717782 |\n",
      "| bedrooms_square  |  None |      0.0      |\n",
      "|    bathrooms     |  None | 15873.9572593 |\n",
      "|   sqft_living    |  None | 32.4102214513 |\n",
      "| sqft_living_sqrt |  None | 690.114773313 |\n",
      "|     sqft_lot     |  None |      0.0      |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |\n",
      "|      floors      |  None |      0.0      |\n",
      "|  floors_square   |  None |      0.0      |\n",
      "|    waterfront    |  None |      0.0      |\n",
      "|       view       |  None |      0.0      |\n",
      "|    condition     |  None |      0.0      |\n",
      "|      grade       |  None | 2899.42026975 |\n",
      "|    sqft_above    |  None | 30.0115753022 |\n",
      "|  sqft_basement   |  None |      0.0      |\n",
      "|     yr_built     |  None |      0.0      |\n",
      "+------------------+-------+---------------+\n",
      "[18 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_last.get(\"coefficients\").print_rows(num_rows = len(all_features)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
